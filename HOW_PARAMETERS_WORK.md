# ğŸ” ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù€ ParametersØŸ

Ø¯Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ Ù„ÙÙ‡Ù… Ø¢Ù„ÙŠØ© Link Crawler ÙÙŠ CyberDev Scanner.

---

## â“ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø´Ø§Ø¦Ø¹

**"Ø¥Ø°Ø§ Ø£Ø¯Ø®Ù„Øª Ø±Ø§Ø¨Ø· Ø¨Ø³ÙŠØ· Ù…Ø«Ù„ `https://example.com`ØŒ ÙƒÙŠÙ ÙŠØ¹Ø±Ù Ø§Ù„Ù…Ø§Ø³Ø­ Ø§Ù„Ù€ parameters (`?id=1`) Ù„ÙØ­Øµ Ø§Ù„Ø«ØºØ±Ø§ØªØŸ"**

---

## âœ… Ø§Ù„Ø¬ÙˆØ§Ø¨: Link Crawler ğŸ•·ï¸

### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:
Ù…Ø¹Ø¸Ù… Ø§Ù„Ø«ØºØ±Ø§Øª ØªØ­ØªØ§Ø¬ parameters:
```
âœ… /page.php?id=1        â†’ Ù‚Ø§Ø¨Ù„ Ù„ÙØ­Øµ SQLi, XSS, LFI
âœ… /search.php?q=test    â†’ Ù‚Ø§Ø¨Ù„ Ù„ÙØ­Øµ XSS, SSTI
âŒ /about.html           â†’ Ø¨Ø¯ÙˆÙ† parametersØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙØ­Øµ
```

### Ø§Ù„Ø­Ù„:
**Link Crawler** ÙŠØ²Ø­Ù Ø§Ù„Ù…ÙˆÙ‚Ø¹ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙˆÙŠÙƒØªØ´Ù URLs Ù…Ø¹ parameters!

---

## ğŸ”„ ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ØŸ (5 Ø®Ø·ÙˆØ§Øª)

### 1ï¸âƒ£ Ø£Ù†Øª ØªØ¯Ø®Ù„ URL Ø¨Ø³ÙŠØ·
```
Input: https://example.com
```

### 2ï¸âƒ£ Crawler ÙŠÙØªØ­ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
```html
<!DOCTYPE html>
<html>
<body>
  <a href="/page.php?id=1">Page 1</a>
  <a href="/search.php?q=test">Search</a>
  <a href="/about.html">About</a>
  <form action="/login.php?redirect=home">...</form>
</body>
</html>
```

### 3ï¸âƒ£ ÙŠØ³ØªØ®Ø±Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
```python
discovered_links = [
    "https://example.com/page.php?id=1",
    "https://example.com/search.php?q=test",
    "https://example.com/about.html",
    "https://example.com/login.php?redirect=home"
]
```

### 4ï¸âƒ£ ÙŠÙÙ„ØªØ± Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙŠ ÙÙŠÙ‡Ø§ parameters
```python
from urllib.parse import urlparse, parse_qs

for link in discovered_links:
    parsed = urlparse(link)
    params = parse_qs(parsed.query)
    
    if params:  # Ø¥Ø°Ø§ ÙÙŠÙ‡ ?param=value
        testable_urls.append(link)

# Ø§Ù„Ù†ØªÙŠØ¬Ø©:
testable_urls = [
    "https://example.com/page.php?id=1",        # âœ“ ÙÙŠÙ‡ ?id=
    "https://example.com/search.php?q=test",    # âœ“ ÙÙŠÙ‡ ?q=
    "https://example.com/login.php?redirect=home" # âœ“ ÙÙŠÙ‡ ?redirect=
    # about.html ØªÙ… ØªØ¬Ø§Ù‡Ù„Ù‡ (Ø¨Ø¯ÙˆÙ† parameters)
]
```

### 5ï¸âƒ£ Ø§Ù„ÙØ§Ø­ØµØ§Øª ØªØ®ØªØ¨Ø± ÙƒÙ„ URL
```python
# ÙÙŠ scanner_orchestrator.py:
for url in testable_urls:
    # ÙØ­Øµ SQLi
    sqli_scanner.scan(url)
    # ÙŠØ¬Ø±Ø¨:
    # - page.php?id=1' OR '1'='1
    # - page.php?id=1' AND SLEEP(5)--
    
    # ÙØ­Øµ XSS
    xss_scanner.scan(url)
    # ÙŠØ¬Ø±Ø¨:
    # - search.php?q=<script>alert(1)</script>
    # - search.php?q=<img src=x onerror=alert(1)>
    
    # ÙØ­Øµ LFI
    lfi_scanner.scan(url)
    # ÙŠØ¬Ø±Ø¨:
    # - page.php?id=../../etc/passwd
    # - page.php?id=..\\..\\windows\\win.ini
```

---

## ğŸ’» Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙØ¹Ù„ÙŠ

### ÙÙŠ `link_crawler.py`:
```python
class LinkCrawler:
    def __init__(self, max_depth=2, max_urls=30):
        self.max_depth = max_depth    # ÙƒÙ… Ù…Ø³ØªÙˆÙ‰ ÙŠØ²Ø­Ù
        self.max_urls = max_urls      # ÙƒÙ… ØµÙØ­Ø© ÙŠØ²ÙˆØ±
    
    def crawl(self, base_url):
        """ÙŠØ²Ø­Ù Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆÙŠÙƒØªØ´Ù URLs."""
        self._crawl_recursive(base_url, depth=0)
        return self.discovered_urls
    
    def _crawl_recursive(self, url, depth):
        """ÙŠØ²Ø­Ù Ø¨Ø´ÙƒÙ„ Ù…ØªÙƒØ±Ø±."""
        if depth > self.max_depth:
            return
        
        # 1. Ø§ÙØªØ­ Ø§Ù„ØµÙØ­Ø©
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 2. Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        for tag in soup.find_all('a', href=True):
            link = urljoin(url, tag['href'])
            
            # 3. ÙÙ„ØªØ±: ÙÙ‚Ø· Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹ parameters
            params = parse_qs(urlparse(link).query)
            if params:
                self.discovered_urls.append({
                    'url': link,
                    'params': list(params.keys()),
                    'depth': depth + 1
                })
            
            # 4. Ø§Ø³ØªÙ…Ø± Ø¨Ø§Ù„Ø²Ø­Ù
            if depth < self.max_depth:
                self._crawl_recursive(link, depth + 1)
    
    def get_testable_urls(self, limit=15):
        """ÙŠØ±Ø¬Ø¹ URLs Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ÙØ­Øµ."""
        return [item['url'] for item in self.discovered_urls[:limit]]
```

### ÙÙŠ `scanner_orchestrator.py`:
```python
class SecurityScanner:
    def __init__(self):
        self.link_crawler = LinkCrawler(max_depth=2, max_urls=30)
        self.sqli_scanner = SQLiScanner()
        self.xss_scanner = XSSScanner()
        # ...
    
    def scan(self, url):
        # 1. Reconnaissance
        recon = self.recon_analyzer.analyze(url)
        
        # 2. Link Crawling â­
        logger.info("Starting link crawler...")
        crawled = self.link_crawler.crawl(url)
        testable_urls = self.link_crawler.get_testable_urls(limit=15)
        
        logger.info(f"Found {len(testable_urls)} testable URLs")
        
        # Ø¥Ø°Ø§ Ù…Ø§ Ù„Ù‚Ù‰ URLsØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù€ URL Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        if not testable_urls:
            testable_urls = [url]
        
        # 3. Vulnerability Scanning
        findings = []
        for test_url in testable_urls:
            findings.extend(self.sqli_scanner.scan(test_url))
            findings.extend(self.xss_scanner.scan(test_url))
            findings.extend(self.lfi_scanner.scan(test_url))
            # ... Ø¨Ø§Ù‚ÙŠ Ø§Ù„ÙØ§Ø­ØµØ§Øª
        
        return ScanResult(findings=findings, ...)
```

---

## ğŸ“Š Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ

### Ø§Ù„Ù…Ø¯Ø®Ù„:
```bash
python main.py
Enter URL: https://testphp.vulnweb.com
```

### Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù€ Logs:
```
[INFO] Starting link crawler...
[DEBUG] Crawling: https://testphp.vulnweb.com/
[DEBUG] Found link: /artists.php?artist=1
[DEBUG] Discovered testable URL: /artists.php?artist=1 âœ“
[DEBUG] Found link: /listproducts.php?cat=1
[DEBUG] Discovered testable URL: /listproducts.php?cat=1 âœ“
[DEBUG] Found link: /about.php
[DEBUG] Ignored (no parameters): /about.php

[INFO] Crawler found 25 URLs, 8 testable URLs

[INFO] [âœ“] Scanning for SQL Injection...
[INFO] [SQLi] Testing: /artists.php?artist=1
[INFO] [SQLi] Payload: artist=1' OR '1'='1
[WARNING] [SQLi] âš ï¸ SQL Injection detected!

[INFO] [âœ“] Scanning for XSS...
[INFO] [XSS] Testing: /artists.php?artist=1
[INFO] [XSS] Payload: artist=<script>alert(1)</script>
```

### Ø§Ù„Ù†ØªÙŠØ¬Ø©:
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ ğŸ“Š SUMMARY OF FINDINGS ]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸ”´ HIGH    : 2
  ğŸŸ  MEDIUM  : 1
  ğŸ”µ LOW     : 3
  ğŸ“Š TOTAL   : 6
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[HIGH] SQL Injection Detected
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Location: /artists.php?artist=1
Description: Boolean-based blind SQLi
Fix: Use parameterized queries
```

---

## âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª

### ØªØ®ØµÙŠØµ Crawler:
```python
# ÙÙŠ scanner_orchestrator.py (Ø§Ù„Ø³Ø·Ø± 53):
self.link_crawler = LinkCrawler(
    max_depth=3,     # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¹Ù…Ù‚ (1, 2, 3, ...)
    max_urls=50      # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª
)

# ÙÙŠ Ø§Ù„Ø³Ø·Ø± 190:
testable_urls = crawler.get_testable_urls(limit=20)  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¯
```

### Ù…ØªÙ‰ ØªØ²ÙŠØ¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§ØªØŸ
- âœ… Ù…ÙˆÙ‚Ø¹ ÙƒØ¨ÙŠØ± ÙˆÙ…Ø¹Ù‚Ø¯ â†’ `max_depth=3, max_urls=100`
- âœ… Ù…ÙˆÙ‚Ø¹ ØµØºÙŠØ± Ø¨Ø³ÙŠØ· â†’ `max_depth=1, max_urls=20`

---

## ğŸ¯ Ù…Ø§Ø°Ø§ Ù„Ùˆ Ù„Ù… ÙŠØ¬Ø¯ URLsØŸ

```python
if not testable_urls:
    logger.warning("No URLs with parameters found")
    testable_urls = [url]  # ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù€ URL Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø·

# Ø§Ù„Ù†ØªÙŠØ¬Ø©:
# Ù…Ø¹Ø¸Ù… Ø§Ù„ÙØ§Ø­ØµØ§Øª Ù„Ù† ØªØ¬Ø¯ Ø´ÙŠØ¡ Ù„Ø£Ù†Ù‡ Ø¨Ø¯ÙˆÙ† parameters
```

**Ø§Ù„Ø­Ù„:**
- ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙÙŠÙ‡ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹ parameters
- Ø¬Ø±Ø¨ Ù…ÙˆÙ‚Ø¹ ØªØ¬Ø±ÙŠØ¨ÙŠ: `http://testphp.vulnweb.com`
- Ø²ÙˆØ¯ `max_depth` Ùˆ `max_urls`

---

## ğŸ” Debugging

### Ø´Ø§Ù‡Ø¯ Ù…Ø§Ø°Ø§ ÙŠÙƒØªØ´Ù Crawler:
```python
# Ø£Ø¶Ù ÙÙŠ scanner_orchestrator.py:
logger.setLevel(logging.DEBUG)

# Ø³ÙŠØ¸Ù‡Ø±:
[DEBUG] Crawling: https://example.com/page1.php
[DEBUG] Found link: /page2.php?id=10
[DEBUG] Discovered testable URL: /page2.php?id=10
[DEBUG] Found link: /page3.html
[DEBUG] Ignored: /page3.html (no parameters)
```

---

## ğŸ“š Ø§Ù„Ù…Ù„ÙØ§Øª Ø°Ø§Øª Ø§Ù„Ø¹Ù„Ø§Ù‚Ø©

| Ø§Ù„Ù…Ù„Ù | Ø§Ù„ÙˆØ¸ÙŠÙØ© |
|-------|---------|
| `scanner/recon/link_crawler.py` | Ø²Ø­Ù ÙˆÙÙ„ØªØ±Ø© URLs |
| `scanner/core/scanner_orchestrator.py` | Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Crawler ÙˆØªÙ…Ø±ÙŠØ± URLs Ù„Ù„ÙØ§Ø­ØµØ§Øª |
| `scanner/vulnerabilities/vuln_*.py` | ÙØ­Øµ ÙƒÙ„ URL |

---

## ğŸ’¡ Ù…Ù„Ø®Øµ Ø³Ø±ÙŠØ¹

```
ğŸ¯ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ù…Ø¹Ø¸Ù… Ø§Ù„Ø«ØºØ±Ø§Øª ØªØ­ØªØ§Ø¬ parameters
âœ… Ø§Ù„Ø­Ù„: Link Crawler ÙŠÙƒØªØ´ÙÙ‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
ğŸ”„ Ø§Ù„Ø¢Ù„ÙŠØ©:
   1. Ø²Ø­Ù Ø§Ù„Ù…ÙˆÙ‚Ø¹
   2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
   3. ÙÙ„ØªØ±Ø© URLs Ù…Ø¹ parameters
   4. Ø§Ù„ÙØ§Ø­ØµØ§Øª ØªØ®ØªØ¨Ø± ÙƒÙ„ URL
ğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø©: ÙƒØ´Ù Ø´Ø§Ù…Ù„ Ù„Ù„Ø«ØºØ±Ø§Øª Ø¨Ø¯ÙˆÙ† Ø¥Ø¯Ø®Ø§Ù„ ÙŠØ¯ÙˆÙŠ!
```

---

**ğŸ‰ Ø§Ù„Ø¢Ù† ÙÙ‡Ù…Øª ÙƒÙŠÙ ÙŠÙƒØªØ´Ù CyberDev Ø§Ù„Ù€ parameters ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹!**
